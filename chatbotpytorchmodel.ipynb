{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatbotpytorchmodel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD1-CSns3gTm"
      },
      "source": [
        "#Description about the project\r\n",
        " This is Natural Language Processing project for E-commerce dataset in a json format with about 7 different classes of tags that could help user get fmailiar with the chatbot using pytorch CNN model Neural Net \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpLC7MMspyDU"
      },
      "source": [
        "#importing neccessary libraries\r\n",
        "import torch\r\n",
        "from torch.jit import script, trace\r\n",
        "import torch.nn as nn\r\n",
        "from torch import optim\r\n",
        "import torch.nn.functional as F\r\n",
        "import csv\r\n",
        "import random\r\n",
        "import re\r\n",
        "import os\r\n",
        "import unicodedata\r\n",
        "import codecs\r\n",
        "from io import open\r\n",
        "import itertools\r\n",
        "import math\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "USE_CUDA = torch.cuda.is_available()\r\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHplBqRDqYu1"
      },
      "source": [
        "import nltk\r\n",
        "from nltk.stem.porter import PorterStemmer\r\n",
        "stemmer = PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scZ_w2kMqjJz",
        "outputId": "e31152b1-6ae8-4de3-dd63-aee55c37fa2b"
      },
      "source": [
        "#nlp pipleines \r\n",
        "nltk.download('punkt')  #a package with a pre-trained tokenized words\r\n",
        "def tokenize(sentence):\r\n",
        "    return nltk.word_tokenize(sentence)\r\n",
        "\r\n",
        "def stem(word):\r\n",
        "    return stemmer.stem(word.lower()) \r\n",
        "\r\n",
        "def bag_of_words(tokenized_sentence, all_word):\r\n",
        "    tokenized_sentence = [stem(w) for w in tokenized_sentence]\r\n",
        "    bag = np.zeros(len(all_word), dtype=np.float32)\r\n",
        "    for idx, w in enumerate(all_word):\r\n",
        "        if w in tokenized_sentence:\r\n",
        "            bag[idx] = 1.0\r\n",
        "    return bag"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dA5lQ_Aaqpzy",
        "outputId": "9b094b4f-c4c1-49e6-f0c0-3a16c5003f36"
      },
      "source": [
        "#testing different nlp pipelines task on different examples \r\n",
        "a = 'See you later, thanks for visiting'\r\n",
        "print(a)\r\n",
        "b = tokenize(a)\r\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "See you later, thanks for visiting\n",
            "['See', 'you', 'later', ',', 'thanks', 'for', 'visiting']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKQ2sP8EqvBy",
        "outputId": "da19a84e-2337-4e52-a42c-a94110559bbf"
      },
      "source": [
        "s = 'organizing', 'organization', 'organ'\r\n",
        "print(s)\r\n",
        "s=[stem(w) for w in s]\r\n",
        "print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('organizing', 'organization', 'organ')\n",
            "['organ', 'organ', 'organ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrcgcuYiq-yi",
        "outputId": "ed4fc9c8-114e-46ad-fcd9-e334fe34245f"
      },
      "source": [
        "sentence = [\"hello\", \"how\", \"are\", \"you\"]\r\n",
        "words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\r\n",
        "bg = bag_of_words(sentence, words)\r\n",
        "print(bg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-JqN85WrEh3"
      },
      "source": [
        "#reading the json datataset file\r\n",
        "import json\r\n",
        "with open('intent.json', 'r') as f:\r\n",
        "    intents = json.load(f)\r\n",
        "#print(intents)\r\n",
        "all_words = []\r\n",
        "tags = []\r\n",
        "patternresponse = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "louQfuTzrXU8"
      },
      "source": [
        "#loop through the tags (classes)\r\n",
        "for intent in intents['intents']:\r\n",
        "    tag = intent['tag']\r\n",
        "    tags.append(tag)\r\n",
        "    for pattern in intent['patterns']:\r\n",
        "        w = tokenize(pattern)\r\n",
        "        all_words.extend(w)\r\n",
        "        patternresponse.append((w,tag))\r\n",
        "\r\n",
        "ignore_words = ['?', '!', '/', '#', '@', ',','.']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqqaDVRsrjwP",
        "outputId": "f8906d91-f403-4dd3-fda1-b0440ca04390"
      },
      "source": [
        "#apply steeming (nlp) to the dataset\r\n",
        "all_words = (stem(w) for w in all_words if w not in ignore_words)\r\n",
        "all_words =sorted(set(all_words))\r\n",
        "tags =sorted(set(tags))\r\n",
        "print(tags)\r\n",
        "print(all_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['delivery', 'funny', 'goodbye', 'greeting', 'items', 'payments', 'thanks']\n",
            "[\"'s\", 'a', 'accept', 'anyon', 'are', 'bye', 'can', 'card', 'cash', 'credit', 'day', 'deliveri', 'do', 'doe', 'funni', 'get', 'good', 'goodby', 'have', 'hello', 'help', 'hey', 'hi', 'how', 'i', 'is', 'item', 'joke', 'kind', 'know', 'later', 'long', 'lot', 'mastercard', 'me', 'my', 'of', 'onli', 'pay', 'paypal', 'see', 'sell', 'ship', 'someth', 'take', 'tell', 'thank', 'that', 'there', 'what', 'when', 'which', 'with', 'you']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNVqfBFyrq1O"
      },
      "source": [
        "#splitting the train dataset\r\n",
        "X_train = []\r\n",
        "y_train = []\r\n",
        "\r\n",
        "for (pattern_sentence, tag) in patternresponse:\r\n",
        "        bag = bag_of_words(pattern_sentence, all_words)\r\n",
        "        X_train.append(bag)\r\n",
        "\r\n",
        "        label = tags.index(tag)\r\n",
        "        y_train.append(label)\r\n",
        "\r\n",
        "X_train= np.array(X_train)\r\n",
        "y_train = np.array(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk78fZKGrz21"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foFMNvDhsApr"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WVWT445roSH"
      },
      "source": [
        "#creating a chat dataset \r\n",
        "class Chatdataset(Dataset):\r\n",
        "    def __init__(self):\r\n",
        "        self.n_sample = len(X_train)\r\n",
        "        self.x_data = X_train\r\n",
        "        self.y_data = y_train\r\n",
        "#Dataset(idx)\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        return self.x_data[index], self.y_data[index]\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return self.n_sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29NdcSfF8vzF",
        "outputId": "79ddbec7-d6f3-4fed-efbd-2c7a9124139e"
      },
      "source": [
        "#hyperparameters for the cnn model\r\n",
        "num_epochs = 1000\r\n",
        "batch_size = 8\r\n",
        "learning_rate = 0.001\r\n",
        "input_size = len(X_train[0])\r\n",
        "hidden_size = 8\r\n",
        "output_size = len(tags)\r\n",
        "print(input_size, output_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgNBGm1MsIsr"
      },
      "source": [
        "dataset = Chatdataset()\r\n",
        "train_dataset = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=2)\r\n",
        "#running the model to cuda for quick runtime\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ody3JKYsbdw"
      },
      "source": [
        "class NeuralNet(nn.Module):\r\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\r\n",
        "#The model is a Feed Forward NN 2 hidden layers and 1 input layer'''\r\n",
        "        super(NeuralNet, self).__init__()\r\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)  \r\n",
        "        self.l2 = nn.Linear(hidden_size, hidden_size)\r\n",
        "        self.l3 = nn.Linear(hidden_size, num_classes)\r\n",
        "        self.relu = nn.ReLU()\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        out = self.l1(x)\r\n",
        "        out = self.relu(out)\r\n",
        "\r\n",
        "        out = self.l1(x)\r\n",
        "        out = self.relu(out)\r\n",
        "\r\n",
        "        out = self.l2(out)\r\n",
        "        out = self.relu(out)\r\n",
        "\r\n",
        "        out = self.l3(out)\r\n",
        "        #no relu or activation \r\n",
        "\r\n",
        "        return out "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poqNgKbqsG_U"
      },
      "source": [
        "#making the model an object and passing arguments to run with on GPU or CPU platform\r\n",
        "model = NeuralNet(input_size, hidden_size, output_size).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGvIjrJNsSF0",
        "outputId": "7ec874c9-48d0-404b-e483-080f9b66575a"
      },
      "source": [
        "#loss and optimizer \r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\r\n",
        "correct = 0\r\n",
        "total = 0\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    for (words, labels) in train_dataset:\r\n",
        "        words = words.to(device)\r\n",
        "        labels = labels.to(dtype=torch.long).to(device)\r\n",
        "        \r\n",
        "        # Forward pass\r\n",
        "        outputs = model(words)\r\n",
        "        # if y would be one-hot, we must apply\r\n",
        "        # labels = torch.max(labels, 1)[1]\r\n",
        "        loss = criterion(outputs, labels)\r\n",
        "    \r\n",
        "        #backwards \r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        _, predicted = torch.max(outputs.data, 1)\r\n",
        "        correct += (predicted == labels).sum().item()\r\n",
        "        total += labels.size(0)\r\n",
        "\r\n",
        "\r\n",
        "        if (epoch+1) % 100 == 0:\r\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:2f}')\r\n",
        "\r\n",
        "\r\n",
        "print(f'final loss: {loss.item():.4f}')\r\n",
        "print(f'final accuracy: {accuracy:.2f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [100/1000], Loss: 0.8623, Accuracy: 100.000000\n",
            "Epoch [100/1000], Loss: 1.1597, Accuracy: 100.000000\n",
            "Epoch [100/1000], Loss: 0.9810, Accuracy: 100.000000\n",
            "Epoch [100/1000], Loss: 0.6250, Accuracy: 100.000000\n",
            "Epoch [200/1000], Loss: 0.1337, Accuracy: 100.000000\n",
            "Epoch [200/1000], Loss: 0.1152, Accuracy: 100.000000\n",
            "Epoch [200/1000], Loss: 0.2386, Accuracy: 100.000000\n",
            "Epoch [200/1000], Loss: 0.0712, Accuracy: 100.000000\n",
            "Epoch [300/1000], Loss: 0.0381, Accuracy: 100.000000\n",
            "Epoch [300/1000], Loss: 0.0189, Accuracy: 100.000000\n",
            "Epoch [300/1000], Loss: 0.0547, Accuracy: 100.000000\n",
            "Epoch [300/1000], Loss: 0.0241, Accuracy: 100.000000\n",
            "Epoch [400/1000], Loss: 0.0084, Accuracy: 100.000000\n",
            "Epoch [400/1000], Loss: 0.0181, Accuracy: 100.000000\n",
            "Epoch [400/1000], Loss: 0.0134, Accuracy: 100.000000\n",
            "Epoch [400/1000], Loss: 0.0209, Accuracy: 100.000000\n",
            "Epoch [500/1000], Loss: 0.0093, Accuracy: 100.000000\n",
            "Epoch [500/1000], Loss: 0.0055, Accuracy: 100.000000\n",
            "Epoch [500/1000], Loss: 0.0052, Accuracy: 100.000000\n",
            "Epoch [500/1000], Loss: 0.0101, Accuracy: 100.000000\n",
            "Epoch [600/1000], Loss: 0.0029, Accuracy: 100.000000\n",
            "Epoch [600/1000], Loss: 0.0038, Accuracy: 100.000000\n",
            "Epoch [600/1000], Loss: 0.0043, Accuracy: 100.000000\n",
            "Epoch [600/1000], Loss: 0.0077, Accuracy: 100.000000\n",
            "Epoch [700/1000], Loss: 0.0018, Accuracy: 100.000000\n",
            "Epoch [700/1000], Loss: 0.0041, Accuracy: 100.000000\n",
            "Epoch [700/1000], Loss: 0.0019, Accuracy: 100.000000\n",
            "Epoch [700/1000], Loss: 0.0008, Accuracy: 100.000000\n",
            "Epoch [800/1000], Loss: 0.0019, Accuracy: 100.000000\n",
            "Epoch [800/1000], Loss: 0.0012, Accuracy: 100.000000\n",
            "Epoch [800/1000], Loss: 0.0020, Accuracy: 100.000000\n",
            "Epoch [800/1000], Loss: 0.0007, Accuracy: 100.000000\n",
            "Epoch [900/1000], Loss: 0.0011, Accuracy: 100.000000\n",
            "Epoch [900/1000], Loss: 0.0010, Accuracy: 100.000000\n",
            "Epoch [900/1000], Loss: 0.0013, Accuracy: 100.000000\n",
            "Epoch [900/1000], Loss: 0.0011, Accuracy: 100.000000\n",
            "Epoch [1000/1000], Loss: 0.0013, Accuracy: 100.000000\n",
            "Epoch [1000/1000], Loss: 0.0005, Accuracy: 100.000000\n",
            "Epoch [1000/1000], Loss: 0.0006, Accuracy: 100.000000\n",
            "Epoch [1000/1000], Loss: 0.0012, Accuracy: 100.000000\n",
            "final loss: 0.0012\n",
            "final accuracy: 100.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpRxfkrQsq3A",
        "outputId": "1a97c5e5-eae7-4669-f932-c82ae58fd473"
      },
      "source": [
        "data = {\r\n",
        "    \"model_state\":model.state_dict(),\r\n",
        "    \"input_size\":input_size,\r\n",
        "    \"output_size\":output_size,\r\n",
        "    \"hidden_size\":hidden_size,\r\n",
        "    \"all_words\": all_words,\r\n",
        "    \"tags\": tags\r\n",
        "}\r\n",
        "\r\n",
        "FILE = 'data.pth' #extension to save file in pytorch\r\n",
        "torch.save(data,FILE)\r\n",
        "\r\n",
        "print(\"training completed, save to {FILE}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training completed, save to {FILE}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7YAAr-3zK3y",
        "outputId": "be948e51-4045-4351-8dd3-62baabf6a5db"
      },
      "source": [
        "#building a non-AI run code for the NN model built \r\n",
        "with open('/content/intent.json', 'r') as json_data:\r\n",
        "    intents = json.load(json_data)\r\n",
        "\r\n",
        "FILE = \"data.pth\"\r\n",
        "data = torch.load(FILE)\r\n",
        "\r\n",
        "input_size = data[\"input_size\"]\r\n",
        "hidden_size = data[\"hidden_size\"]\r\n",
        "output_size = data[\"output_size\"]\r\n",
        "all_words = data['all_words']\r\n",
        "tags = data['tags']\r\n",
        "model_state = data[\"model_state\"]\r\n",
        "\r\n",
        "model = NeuralNet(input_size, hidden_size, output_size).to(device)\r\n",
        "model.load_state_dict(model_state)\r\n",
        "model.eval()\r\n",
        "\r\n",
        "bot_name = \"Jude\"\r\n",
        "print(\"Let's chat! (type 'quit' to exit)\")\r\n",
        "while True:\r\n",
        "    # sentence = \"do you use credit cards?\"\r\n",
        "    sentence = input(\"You: \")\r\n",
        "    if sentence == \"quit\":\r\n",
        "        break\r\n",
        "\r\n",
        "    sentence = tokenize(sentence)\r\n",
        "    X = bag_of_words(sentence, all_words)\r\n",
        "    X = X.reshape(1, X.shape[0])\r\n",
        "    X = torch.from_numpy(X).to(device)\r\n",
        "\r\n",
        "    output = model(X)\r\n",
        "    _, predicted = torch.max(output, dim=1)\r\n",
        "\r\n",
        "    tag = tags[predicted.item()]\r\n",
        "\r\n",
        "    probs = torch.softmax(output, dim=1)\r\n",
        "    prob = probs[0][predicted.item()]\r\n",
        "\r\n",
        "    if prob.item() > 0.75:\r\n",
        "        for intent in intents['intents']:\r\n",
        "            if tag == intent[\"tag\"]:\r\n",
        "                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\r\n",
        "    else:\r\n",
        "        print(f\"{bot_name}: I do not understand...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's chat! (type 'quit' to exit)\n",
            "You: hello\n",
            "Israel: Hello, thanks for visiting\n",
            "You: what do you sell\n",
            "Israel: We sell coffee and tea\n",
            "You: what is the cost\n",
            "Israel: Hello, thanks for visiting\n",
            "You: what is the price\n",
            "Israel: Hello, thanks for visiting\n",
            "You: what is the delivery \n",
            "Israel: I do not understand...\n",
            "You: how do you make payment \n",
            "Israel: Hi there, what can I do for you?\n",
            "You: how to pay\n",
            "Israel: Hi there, how can I help?\n",
            "You: do take cash\n",
            "Israel: We accept most major credit cards, and Paypal\n",
            "You: how about mode of delivery\n",
            "Israel: I do not understand...\n",
            "You: deliver goods\n",
            "Israel: Hello, thanks for visiting\n",
            "You: quit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B43RjHNC5Hjq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WatDoa5gzX-k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}